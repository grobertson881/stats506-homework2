---
title: "Homework2"
format:
  html:
    code-fold: true
    code-summary: "Show the code"
    embed-resources: true
editor: visual
---

Link to Github repository: https://github.com/grobertson881/stats506-homework2

**Problem 1**

*Part A*

```{r}
# for loop
random_walk1 <- function(n) {
  firststeps <- ifelse(runif(n) < 0.5, -1, 1)
  steps <- numeric(n)
  
  for (i in 1:n) {
    if (firststeps[i] == 1) {
      steps[i] <- ifelse(runif(1) < 0.95, 1, 10)
    } else {
      steps[i] <- ifelse(runif(1) < 0.80, -1, -3)
    }
  }
  return(sum(steps))
}

# R vectorized functions
random_walk2 <- function(n) {
  steps <- ifelse(runif(n) < 0.5, -1, 1)
  
  positives <- which(steps == 1)
  positivesteps <- ifelse(runif(length(positives)) < 0.95, 1, 10)
  steps[positives] <- positivesteps
  
  negatives <- which(steps == -1)
  negativesteps <- ifelse(runif(length(negatives)) < 0.80, -1, -3)
  steps[negatives] <- negativesteps
  
  return(sum(steps))
}

# apply functions
random_walk3 <- function(n) {
  steps <- ifelse(runif(n) < 0.5, -1, 1)
  
  positives <- which(steps == 1)
  positivesteps = sapply(positives, function(x) 
    {ifelse(runif(1) < 0.95, 1, 10)})
  steps[positives] <- positivesteps
  
  negatives <- which(steps == -1)
  negativesteps = sapply(negatives, function(x) 
    {ifelse(runif(1) < 0.80, -1, -3)})
  steps[negatives] <- negativesteps
  
  return(sum(steps))
}

random_walk1(10)
random_walk2(10)
random_walk3(10)
random_walk1(1000)
random_walk2(1000)
random_walk3(1000)
```

*Part B*

```{r}
set.seed(25)
random_walk1(10)

set.seed(25)
random_walk2(10)

set.seed(25)
random_walk3(10)

set.seed(25)
random_walk1(1000)

set.seed(25)
random_walk2(1000)

set.seed(25)
random_walk3(1000)

```
The functions work for the input value of 100, but when increasing the input value to 1000 the differences in how the functions process randomness changes. The for loop makes calls to get a random number much more times than the other two functions. This difference doesn't show at a smaller number, but with a huge input the difference is exposed. In order to fix this, the for loop function would have to be changed to take the random processes out of the loop. It would have to create a vector of the random values, then the for loop would just be putting the correct value into the step vector based on the random values generated earlier. 

*Part C*

```{r}
library(microbenchmark)

microbenchmark(
  random1 = random_walk1(1000),
  random2 = random_walk2(1000),
  random3 = random_walk3(1000)
)
```
```{r}
microbenchmark(
  random1 = random_walk1(10000),
  random2 = random_walk2(10000),
  random3 = random_walk3(10000)
)
```

*Part D*

```{r}
montecarlo <- function(n, sims = 10000) {
  zerocounter <- 0
  for (i in 1:sims) {
    currentoutput <- random_walk2(n)
    if (currentoutput == 0) {
      zerocounter <- zerocounter + 1
    }
  }
  prob <- zerocounter / sims
  return(prob)
}

n1 <- 10
n2 <- 100
n3 <- 1000

montecarlo(n1)
montecarlo(n2)
montecarlo(n3)

```
There is a 13% chance of ending at one for n = 10, a 1.9% chance of ending at one for n = 100, and a 0.47% chance of ending at one for n = 1000.

**Problem 2**
```{r}
# between midnight until 7 (7 hours)
    # lambda <- 1
# between 9 to 4 (7 hours)
    # lambda <- 8
# between 6 to 11 (5 hours)
    # lambda <- 12
# between 8 to 9 and 5 to 6 (2 hours)
    # mean <- 60
    # var <- 12
# note: don't have data for 7-8am or 11pm-12am

n = 10000000
day_avg = (7*mean(rpois(n, 1))) + (7*mean(rpois(n,8))) + 
          (5*mean(rpois(n,12))) + (2*mean(rnorm(n, 60, 12)))
print(paste("The average cars per day is:", format(day_avg, digits = 3)))
```

**Problem 3**
```{r}
youtube <- read.csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-02/youtube.csv')
```

*Part A*
```{r}
library(dplyr)

deidentified <- youtube %>%
  select(-brand, -superbowl_ads_dot_com_url, -youtube_url, -id, -etag, -published_at, 
         -title, -description, -thumbnail, -channel_title)

deidentify_nona <- na.omit(deidentified)
dimen <- dim(deidentify_nona)

print(paste("Dimensions of de-identified data is: ", dimen[1], ",", dimen[2], sep=""))
```
There are 15 columns with 247 rows of observations.

*Part B*
```{r}
max(deidentify_nona$view_count)
max(deidentify_nona$like_count)
max(deidentify_nona$dislike_count)
max(deidentify_nona$favorite_count)
max(deidentify_nona$comment_count)

min(deidentify_nona$favorite_count)
```
The view counts, like counts, dislike counts, and comment counts can be used as the outcome of a linear regression model because they are continuous in this case. The favorite count would not be appropriate to use in this context because all the values in this column are 0s. This would cause unexpected or unrepresentative outcomes of the model. 

*Part C*
```{r}
viewmodel <- lm(view_count ~ funny + show_product_quickly + patriotic + celebrity + 
                  danger + animals + use_sex + year, deidentify_nona)

likemodel <- lm(like_count ~ funny + show_product_quickly + patriotic + celebrity + 
                  danger + animals + use_sex + year, deidentify_nona)

dislikemodel <- lm(dislike_count ~ funny + show_product_quickly + patriotic + celebrity + 
                  danger + animals + use_sex + year, deidentify_nona)

commentmodel <- lm(comment_count ~ funny + show_product_quickly + patriotic + celebrity + 
                  danger + animals + use_sex + year, deidentify_nona)

summary(viewmodel)
summary(likemodel)
summary(dislikemodel)
summary(commentmodel)
```
Overall, the results showing correlation are not very significant. The only p values that were less than 0.05 were for patriotic (TRUE) and year being a predictor of comment counts. It seems that the counts are difficult to predict from these binary values. 

*Part D*
```{r}
viewmatrix <- model.matrix(~ funny + show_product_quickly + patriotic + celebrity + 
                  danger + animals + use_sex, deidentify_nona)
views <- deidentify_nona$view_count
beta <- solve(t(viewmatrix) %*% viewmatrix) %*% t(viewmatrix) %*% views
coef(viewmodel)
beta
```
